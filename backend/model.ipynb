{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': {'name': 'Bangalore', 'region': 'Karnataka', 'country': 'India', 'lat': 12.98, 'lon': 77.58, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1716579469, 'localtime': '2024-05-25 1:07'}, 'current': {'last_updated_epoch': 1716579000, 'last_updated': '2024-05-25 01:00', 'temp_c': 22.0, 'temp_f': 71.6, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 15.0, 'wind_kph': 24.1, 'wind_degree': 320, 'wind_dir': 'NW', 'pressure_mb': 1009.0, 'pressure_in': 29.8, 'precip_mm': 0.06, 'precip_in': 0.0, 'humidity': 88, 'cloud': 75, 'feelslike_c': 24.5, 'feelslike_f': 76.1, 'vis_km': 6.0, 'vis_miles': 3.0, 'uv': 1.0, 'gust_mph': 17.6, 'gust_kph': 28.3}}\n",
      "Current weather in Bangalore:\n",
      "Temperature: 22.0Â°C\n",
      "Condition: Partly cloudy\n",
      "Wind Speed: 24.1 kph\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(city):\n",
    "    api_key = \"9e75102f2a1049a78a382719242005\"\n",
    "    api_url = f\"https://api.weatherapi.com/v1/current.json?key={api_key}&q={city}&aqi=no\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()  # Raise an exception for non-2xx status codes\n",
    "        weather_data = response.json()\n",
    "        return weather_data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "city = \"Bangalore\"\n",
    "weather_info = get_weather(city)\n",
    "print(weather_info)\n",
    "if weather_info:\n",
    "    print(f\"Condition: {weather_info['current']['condition']['text']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Failed to fetch weather data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "li=[weather_info['current']['wind_mph'],weather_info['current']['pressure_mb'],weather_info['current']['precip_mm'],weather_info['current']['humidity'],weather_info['current']['vis_miles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_heavily_raining(precip_mm, humidity, wind_mph):\n",
    "    if precip_mm >= 10:\n",
    "        # If precipitation is greater than or equal to 10 mm, it's considered heavy rain\n",
    "        return True\n",
    "    elif precip_mm > 0 and humidity >= 90 and wind_mph <= 10:\n",
    "        # If there's precipitation, high humidity, and low wind speed,\n",
    "        # it might be heavy rain\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_heavy_fog(visibility_miles):\n",
    "    # Heavy fog is typically considered when visibility is less than 0.25 miles\n",
    "    if visibility_miles < 0.25:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_heavily_raining(li[2], li[3], li[0]):\n",
    "     rain =1\n",
    "else:\n",
    "    rain =0\n",
    "if is_heavy_fog(li[4]):\n",
    "    fog =1\n",
    "else:\n",
    "    fog =0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         datetime_utc   dewptm   fog   humidty   pressurem   rain   snow  \\\n",
      "0      19961101-11:00      9.0     0      27.0      1010.0      0      0   \n",
      "1      19961101-14:00     10.0     0      41.0      1010.0      0      0   \n",
      "2      19961101-16:00     11.0     0      47.0      1011.0      0      0   \n",
      "3      19961101-17:00     12.0     0      56.0      1011.0      0      0   \n",
      "4      19961101-18:00     13.0     0      60.0      1010.0      0      0   \n",
      "...               ...      ...   ...       ...         ...    ...    ...   \n",
      "97171  20170424-06:00     17.0     0      25.0      1005.0      0      0   \n",
      "97172  20170424-09:00     14.0     0      16.0      1003.0      0      0   \n",
      "97173  20170424-12:00     12.0     0      14.0      1002.0      0      0   \n",
      "97174  20170424-15:00     15.0     0      27.0      1004.0      0      0   \n",
      "97175  20170424-18:00     15.0     0      30.0      1005.0      0      0   \n",
      "\n",
      "        thunder   tornado   wspdm  Overall conds    vector  \n",
      "0             0         0     7.4          Smoke -0.026776  \n",
      "1             0         0     0.0          Smoke -0.026776  \n",
      "2             0         0     0.0          Smoke -0.026776  \n",
      "3             0         0     0.0          Smoke -0.026776  \n",
      "4             0         0     0.0          Smoke -0.026776  \n",
      "...         ...       ...     ...            ...       ...  \n",
      "97171         0         0    11.1           Haze  0.015248  \n",
      "97172         0         0    22.2           Haze  0.015248  \n",
      "97173         0         0    18.5           Haze  0.015248  \n",
      "97174         0         0     3.7           Haze  0.015248  \n",
      "97175         0         0     3.7           Haze  0.015248  \n",
      "\n",
      "[97176 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x=pd.read_csv(\"weather2.csv\")\n",
    "x=pd.DataFrame(x)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smoke' 'Clear' 'Haze' 'Unknown' 'Scattered Clouds' 'Shallow Fog'\n",
      " 'Mostly Cloudy' 'Fog' 'Partly Cloudy' 'Patches of Fog'\n",
      " 'Thunderstorms and Rain' 'Overcast' 'Rain' 'Light Rain' 'Light Drizzle'\n",
      " 'Drizzle' 'Mist' 'Volcanic Ash' 'Thunderstorm'\n",
      " 'Light Thunderstorms and Rain' 'Light Thunderstorm' 'Squalls'\n",
      " 'Heavy Rain' 'Light Haze' 'Sandstorm' 'Widespread Dust' 'Funnel Cloud'\n",
      " 'Heavy Thunderstorms and Rain' 'Heavy Thunderstorms with Hail'\n",
      " 'Light Rain Showers' 'Thunderstorms with Hail' nan 'Partial Fog'\n",
      " 'Light Fog' 'Heavy Fog' 'Blowing Sand' 'Light Hail Showers'\n",
      " 'Light Sandstorm' 'Light Freezing Rain' 'Rain Showers']\n"
     ]
    }
   ],
   "source": [
    "# find unique elements name in the column\n",
    "print(x[' Overall conds'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_corpus = [\n",
    "    \"Clear skies are good weather\",\n",
    "    \"Scattered clouds are generally good weather\",\n",
    "    \"Partly cloudy is acceptable weather\",\n",
    "    \"Mostly cloudy can be tricky weather\",\n",
    "    \"Overcast is not great weather\",\n",
    "    \"Light haze can be annoying weather\",\n",
    "    \"Haze is bad for visibility\",\n",
    "    \"Shallow fog is bad weather for flying\",\n",
    "    \"Mist is bad weather for visibility\",\n",
    "    \"Light fog is challenging for flying\",\n",
    "    \"Fog is very bad for visibility\",\n",
    "    \"Patches of fog are bad for flying\",\n",
    "    \"Partial fog is bad for flying\",\n",
    "    \"Heavy fog is very bad for flying\",\n",
    "    \"Light drizzle is light rain\",\n",
    "    \"Drizzle is light rain\",\n",
    "    \"Light rain is not ideal weather\",\n",
    "    \"Rain is bad for flights\",\n",
    "    \"Heavy rain is very bad for flights\",\n",
    "    \"Light freezing rain is bad for flights\",\n",
    "    \"Thunderstorm is bad weather\",\n",
    "    \"Light thunderstorm is tricky weather\",\n",
    "    \"Light thunderstorms and rain are bad\",\n",
    "    \"Thunderstorms and rain are very bad\",\n",
    "    \"Heavy thunderstorms and rain are very bad\",\n",
    "    \"Heavy thunderstorms with hail are very bad\",\n",
    "    \"Thunderstorms with hail are very bad\",\n",
    "    \"Funnel cloud is dangerous weather\",\n",
    "    \"Smoke is bad for visibility\",\n",
    "    \"Widespread dust is bad for visibility\",\n",
    "    \"Blowing sand is dangerous weather\",\n",
    "    \"Sandstorm is dangerous weather\",\n",
    "    \"Light sandstorm is tricky weather\",\n",
    "    \"Volcanic ash is dangerous weather\",\n",
    "    \"Squalls are very dangerous\",\n",
    "    \"Light hail showers are bad weather\",\n",
    "    \"Unknown weather conditions are tricky\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Smoke': -0.026779109692259027, 'Clear': -0.05195061212345827, 'Haze': 0.015132008001813696, 'Unknown': -0.030485114635679437, 'Scattered Clouds': 0.0009902988718903066, 'Shallow Fog': 0.0009902988718903049, 'Mostly Cloudy': 0.0009902988718903049, 'Fog': 0.026117251509487675, 'Partly Cloudy': 0.0009902988718903049, 'Patches of Fog': 0.0009902988718903049, 'Thunderstorms and Rain': 0.0009902988718903049, 'Overcast': -0.05276155823279847, 'Rain': -0.011937288322677717, 'Light Rain': 0.0009902988718903049, 'Light Drizzle': 0.0009902988718903049, 'Drizzle': 0.00800831027196088, 'Mist': 0.02689823853956151, 'Volcanic Ash': 0.0009902988718903049, 'Thunderstorm': -0.01584272903280407, 'Light Thunderstorms and Rain': 0.0009902988718903049, 'Light Thunderstorm': 0.0009902988718903049, 'Squalls': 0.018567200573730822, 'Heavy Rain': 0.0009902988718903049, 'Light Haze': 0.0009902988718903049, 'Sandstorm': 0.0682953336020841, 'Widespread Dust': 0.0009902988718903049, 'Funnel Cloud': 0.0009902988718903049, 'Heavy Thunderstorms and Rain': 0.0009902988718903049, 'Heavy Thunderstorms with Hail': 0.0009902988718903049, 'Light Rain Showers': 0.0009902988718903049, 'Thunderstorms with Hail': 0.0009902988718903049, 'Partial Fog': 0.0009902988718903049, 'Light Fog': 0.0009902988718903049, 'Heavy Fog': 0.0009902988718903049, 'Blowing Sand': 0.0009902988718903049, 'Light Hail Showers': 0.0009902988718903049, 'Light Sandstorm': 0.0009902988718903049, 'Light Freezing Rain': 0.0009902988718903049, 'Rain Showers': 0.0009902988718903049}\n",
      "The float value for 'Heavy Fog' is 0.0009902988718903049\n",
      "Heavy Fog is bad weather for a flight to fly.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the custom corpus\n",
    "tokenized_corpus = [sentence.lower().split() for sentence in custom_corpus]\n",
    "\n",
    "# Train a Word2Vec model on the custom corpus\n",
    "word2vec_model = Word2Vec(sentences=tokenized_corpus, vector_size=50, window=1, min_count=1, sg=1)\n",
    "\n",
    "# List of weather conditions\n",
    "weather_conditions = [\n",
    "    'Smoke', 'Clear', 'Haze', 'Unknown', 'Scattered Clouds', 'Shallow Fog',\n",
    "    'Mostly Cloudy', 'Fog', 'Partly Cloudy', 'Patches of Fog', 'Thunderstorms and Rain',\n",
    "    'Overcast', 'Rain', 'Light Rain', 'Light Drizzle', 'Drizzle', 'Mist', 'Volcanic Ash',\n",
    "    'Thunderstorm', 'Light Thunderstorms and Rain', 'Light Thunderstorm', 'Squalls',\n",
    "    'Heavy Rain', 'Light Haze', 'Sandstorm', 'Widespread Dust', 'Funnel Cloud',\n",
    "    'Heavy Thunderstorms and Rain', 'Heavy Thunderstorms with Hail', 'Light Rain Showers',\n",
    "    'Thunderstorms with Hail', 'Partial Fog', 'Light Fog', 'Heavy Fog', 'Blowing Sand',\n",
    "    'Light Hail Showers', 'Light Sandstorm', 'Light Freezing Rain', 'Rain Showers'\n",
    "]\n",
    "\n",
    "# Function to get word embeddings\n",
    "def get_embedding(word, model):\n",
    "    try:\n",
    "        return model.wv[word.lower()]\n",
    "    except KeyError:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Get embeddings for each weather condition\n",
    "weather_embeddings = np.array([get_embedding(condition.replace(\" \", \"_\"), word2vec_model) for condition in weather_conditions])\n",
    "\n",
    "# Apply PCA to reduce dimensions to 1\n",
    "pca = PCA(n_components=1)\n",
    "weather_float_values = pca.fit_transform(weather_embeddings)\n",
    "\n",
    "# Convert to a dictionary for easier lookup\n",
    "weather_to_float = {weather_conditions[i]: weather_float_values[i, 0] for i in range(len(weather_conditions))}\n",
    "\n",
    "print(weather_to_float)\n",
    "\n",
    "# Example reasoning for Heavy Fog\n",
    "heavy_fog_value = weather_to_float['Heavy Fog']\n",
    "print(f\"The float value for 'Heavy Fog' is {heavy_fog_value}\")\n",
    "\n",
    "# Define a threshold based on domain knowledge or data analysis\n",
    "threshold = np.mean(list(weather_to_float.values()))  # Example threshold; adjust it based on your criteria\n",
    "\n",
    "if heavy_fog_value > threshold:\n",
    "    print(\"Heavy Fog is bad weather for a flight to fly.\")\n",
    "else:\n",
    "    print(\"Heavy Fog is not considered bad weather for a flight to fly.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Smoke': -0.011132802, 'Clear': 1.0030646, 'Haze': 1.9932828, 'Unknown': 2.996502, 'Scattered Clouds': 4.002086, 'Shallow Fog': 4.9997945, 'Mostly Cloudy': 6.003112, 'Fog': 7.026452, 'Partly Cloudy': 8.002339, 'Patches of Fog': 9.002536, 'Thunderstorms and Rain': 10.001649, 'Overcast': 10.999292, 'Rain': 12.004707, 'Light Rain': 12.998547, 'Light Drizzle': 13.995113, 'Drizzle': 14.996856, 'Mist': 15.996973, 'Volcanic Ash': 16.996101, 'Thunderstorm': 18.0021, 'Light Thunderstorms and Rain': 18.999117, 'Light Thunderstorm': 19.997986, 'Squalls': 20.996948, 'Heavy Rain': 22.000343, 'Light Haze': 22.99874, 'Sandstorm': 24.00104, 'Widespread Dust': 25.000452, 'Funnel Cloud': 25.999273, 'Heavy Thunderstorms and Rain': 27.000769, 'Heavy Thunderstorms with Hail': 28.000671, 'Light Rain Showers': 28.999628, 'Thunderstorms with Hail': 30.001484, 'Partial Fog': 31.000973, 'Light Fog': 31.997368, 'Heavy Fog': 33.00242, 'Blowing Sand': 33.99642, 'Light Hail Showers': 34.999584, 'Light Sandstorm': 35.997112, 'Light Freezing Rain': 36.998135, 'Rain Showers': 38.002163}\n",
      "The float value for 'Heavy Fog' is 33.002418518066406\n",
      "Heavy Fog is bad weather for a flight to fly.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize the custom corpus\n",
    "tokenized_corpus = [sentence.lower().split() for sentence in custom_corpus]\n",
    "\n",
    "# Train a FastText model on the custom corpus\n",
    "fasttext_model = FastText(sentences=tokenized_corpus, vector_size=50, window=1, min_count=1, sg=1)\n",
    "\n",
    "# List of weather conditions\n",
    "weather_conditions = [\n",
    "    'Smoke', 'Clear', 'Haze', 'Unknown', 'Scattered Clouds', 'Shallow Fog',\n",
    "    'Mostly Cloudy', 'Fog', 'Partly Cloudy', 'Patches of Fog', 'Thunderstorms and Rain',\n",
    "    'Overcast', 'Rain', 'Light Rain', 'Light Drizzle', 'Drizzle', 'Mist', 'Volcanic Ash',\n",
    "    'Thunderstorm', 'Light Thunderstorms and Rain', 'Light Thunderstorm', 'Squalls',\n",
    "    'Heavy Rain', 'Light Haze', 'Sandstorm', 'Widespread Dust', 'Funnel Cloud',\n",
    "    'Heavy Thunderstorms and Rain', 'Heavy Thunderstorms with Hail', 'Light Rain Showers',\n",
    "    'Thunderstorms with Hail', 'Partial Fog', 'Light Fog', 'Heavy Fog', 'Blowing Sand',\n",
    "    'Light Hail Showers', 'Light Sandstorm', 'Light Freezing Rain', 'Rain Showers'\n",
    "]\n",
    "\n",
    "# Function to get word embeddings\n",
    "def get_embedding(word, model):\n",
    "    try:\n",
    "        return model.wv[word.lower()]\n",
    "    except KeyError:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Get embeddings for each weather condition\n",
    "weather_embeddings = np.array([get_embedding(condition.replace(\" \", \"_\"), fasttext_model) for condition in weather_conditions])\n",
    "\n",
    "# Apply PCA to reduce dimensions to 1\n",
    "pca = PCA(n_components=1)\n",
    "weather_float_values = pca.fit_transform(weather_embeddings)\n",
    "\n",
    "# Adjusting values to avoid duplication\n",
    "weather_float_values += np.arange(len(weather_conditions)).reshape(-1, 1)\n",
    "\n",
    "# Convert to a dictionary for easier lookup\n",
    "weather_to_float = {weather_conditions[i]: weather_float_values[i, 0] for i in range(len(weather_conditions))}\n",
    "\n",
    "print(weather_to_float)\n",
    "\n",
    "# Example reasoning for Heavy Fog\n",
    "heavy_fog_value = weather_to_float['Heavy Fog']\n",
    "print(f\"The float value for 'Heavy Fog' is {heavy_fog_value}\")\n",
    "\n",
    "# Define a threshold based on domain knowledge or data analysis\n",
    "threshold = np.mean(list(weather_to_float.values()))  # Example threshold; adjust it based on your criteria\n",
    "\n",
    "if heavy_fog_value > threshold:\n",
    "    print(\"Heavy Fog is bad weather for a flight to fly.\")\n",
    "else:\n",
    "    print(\"Heavy Fog is not considered bad weather for a flight to fly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\acer\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\acer\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.2.2)\n",
      "Collecting accelerate>=0.20.3 (from transformers[torch])\n",
      "  Obtaining dependency information for accelerate>=0.20.3 from https://files.pythonhosted.org/packages/e9/bb/1edd2c836071e91d2bd331b9542bbd592e23d1474645b9c6fd56232caace/accelerate-0.30.1-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\acer\\anaconda3\\lib\\site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
      "Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/302.6 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/302.6 kB 393.8 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 71.7/302.6 kB 563.7 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 92.2/302.6 kB 581.0 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 122.9/302.6 kB 554.9 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 143.4/302.6 kB 532.5 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 194.6/302.6 kB 620.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 276.5/302.6 kB 774.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 302.6/302.6 kB 814.4 kB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.30.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\acer\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\acer\\anaconda3\\lib\\site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cb4ff057be44ea8352fba47f02d180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\acer\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7561ba8064a644e39ce01cca6fd0c308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bc5edfddfd4fc7af5cd919e30719cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b380165d3c6744b381dce8e01c3fa912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke: -4.578667163848877\n",
      "Clear: -5.187942028045654\n",
      "Haze: -5.4762654304504395\n",
      "Unknown: -1.4518357515335083\n",
      "Scattered Clouds: -1.8316144943237305\n",
      "Shallow Fog: 1.1688272953033447\n",
      "Mostly Cloudy: -4.091039180755615\n",
      "Fog: -4.836163520812988\n",
      "Partly Cloudy: 0.4274824559688568\n",
      "Patches of Fog: 1.3853352069854736\n",
      "Thunderstorms and Rain: 5.537961959838867\n",
      "Overcast: 4.608304977416992\n",
      "Rain: -2.8355484008789062\n",
      "Light Rain: -0.8421682715415955\n",
      "Light Drizzle: -0.04406352341175079\n",
      "Drizzle: -2.0273935794830322\n",
      "Mist: -3.947756290435791\n",
      "Volcanic Ash: 1.3079012632369995\n",
      "Thunderstorm: 1.5029027462005615\n",
      "Light Thunderstorms and Rain: 5.564636707305908\n",
      "Light Thunderstorm: 1.07584810256958\n",
      "Squalls: 3.149637222290039\n",
      "Heavy Rain: 1.3749312162399292\n",
      "Light Haze: -3.447739601135254\n",
      "Sandstorm: 0.5374147891998291\n",
      "Widespread Dust: -2.6643786430358887\n",
      "Funnel Cloud: -2.443344831466675\n",
      "Heavy Thunderstorms and Rain: 7.3400774002075195\n",
      "Heavy Thunderstorms with Hail: 7.596186637878418\n",
      "Light Rain Showers: 1.9606034755706787\n",
      "Thunderstorms with Hail: 6.89345121383667\n",
      "nan: -5.53714656829834\n",
      "Partial Fog: -2.47829532623291\n",
      "Light Fog: -3.021571636199951\n",
      "Heavy Fog: -1.2129054069519043\n",
      "Blowing Sand: 1.5428192615509033\n",
      "Light Hail Showers: 3.2574281692504883\n",
      "Light Sandstorm: 0.05375947058200836\n",
      "Light Freezing Rain: -0.8092019557952881\n",
      "Rain Showers: 2.479522943496704\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# List of weather conditions\n",
    "weather_conditions = ['Smoke', 'Clear', 'Haze', 'Unknown', 'Scattered Clouds', 'Shallow Fog', 'Mostly Cloudy', 'Fog', 'Partly Cloudy', 'Patches of Fog', 'Thunderstorms and Rain', 'Overcast', 'Rain', 'Light Rain', 'Light Drizzle', 'Drizzle', 'Mist', 'Volcanic Ash', 'Thunderstorm', 'Light Thunderstorms and Rain', 'Light Thunderstorm', 'Squalls', 'Heavy Rain', 'Light Haze', 'Sandstorm', 'Widespread Dust', 'Funnel Cloud', 'Heavy Thunderstorms and Rain', 'Heavy Thunderstorms with Hail', 'Light Rain Showers', 'Thunderstorms with Hail', 'nan', 'Partial Fog', 'Light Fog', 'Heavy Fog', 'Blowing Sand', 'Light Hail Showers', 'Light Sandstorm', 'Light Freezing Rain', 'Rain Showers']\n",
    "\n",
    "# Tokenize the weather conditions and get their embeddings\n",
    "embeddings = []\n",
    "for condition in weather_conditions:\n",
    "    inputs = tokenizer(condition, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    embeddings.append(last_hidden_state.detach().numpy()[0][0])\n",
    "\n",
    "# Convert the embeddings to a numpy array\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Apply PCA to reduce the dimensionality\n",
    "pca = PCA(n_components=1)\n",
    "pca_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "dict={}\n",
    "# Print the single float value for each weather condition\n",
    "for condition, pca_embedding in zip(weather_conditions, pca_embeddings):\n",
    "   \n",
    "\n",
    "    print(f\"{condition}: {pca_embedding[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.578667163848877], [-5.187942028045654], [-5.4762654304504395], [-1.4518357515335083], [-1.8316144943237305], [1.1688272953033447], [-4.091039180755615], [-4.836163520812988], [0.4274824559688568], [1.3853352069854736], [5.537961959838867], [4.608304977416992], [-2.8355484008789062], [-0.8421682715415955], [-0.04406352341175079], [-2.0273935794830322], [-3.947756290435791], [1.3079012632369995], [1.5029027462005615], [5.564636707305908], [1.07584810256958], [3.149637222290039], [1.3749312162399292], [-3.447739601135254], [0.5374147891998291], [-2.6643786430358887], [-2.443344831466675], [7.3400774002075195], [7.596186637878418], [1.9606034755706787], [6.89345121383667], [-5.53714656829834], [-2.47829532623291], [-3.021571636199951], [-1.2129054069519043], [1.5428192615509033], [3.2574281692504883], [0.05375947058200836], [-0.8092019557952881], [2.479522943496704]]\n"
     ]
    }
   ],
   "source": [
    "# convert pcs embedding to list\n",
    "print(pca_embeddings)\n",
    "i=0\n",
    "dic={}\n",
    "for condition in weather_conditions:\n",
    "    dic[condition]=pca_embeddings[i][0]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"vector\"]=x[\" Overall conds\"].map(dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert places wihth -999 with nan value\n",
    "x.replace(-9999, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97176"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove row with nan values in thw row\n",
    "x.dropna(inplace=True)\n",
    "len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          datetime_utc   dewptm   fog   humidty   pressurem   rain   snow  \\\n",
      "0       19961101-11:00      9.0     0      27.0      1010.0      0      0   \n",
      "3       19961101-14:00     10.0     0      41.0      1010.0      0      0   \n",
      "4       19961101-16:00     11.0     0      47.0      1011.0      0      0   \n",
      "5       19961101-17:00     12.0     0      56.0      1011.0      0      0   \n",
      "6       19961101-18:00     13.0     0      60.0      1010.0      0      0   \n",
      "...                ...      ...   ...       ...         ...    ...    ...   \n",
      "100985  20170424-06:00     17.0     0      25.0      1005.0      0      0   \n",
      "100986  20170424-09:00     14.0     0      16.0      1003.0      0      0   \n",
      "100987  20170424-12:00     12.0     0      14.0      1002.0      0      0   \n",
      "100988  20170424-15:00     15.0     0      27.0      1004.0      0      0   \n",
      "100989  20170424-18:00     15.0     0      30.0      1005.0      0      0   \n",
      "\n",
      "         thunder   tornado   wspdm  Overall conds    vector flight_condition  \n",
      "0              0         0     7.4          Smoke -4.578667          optimal  \n",
      "3              0         0     0.0          Smoke -4.578667          optimal  \n",
      "4              0         0     0.0          Smoke -4.578667          optimal  \n",
      "5              0         0     0.0          Smoke -4.578667          optimal  \n",
      "6              0         0     0.0          Smoke -4.578667          optimal  \n",
      "...          ...       ...     ...            ...       ...              ...  \n",
      "100985         0         0    11.1           Haze -5.476265              bad  \n",
      "100986         0         0    22.2           Haze -5.476265              bad  \n",
      "100987         0         0    18.5           Haze -5.476265              bad  \n",
      "100988         0         0     3.7           Haze -5.476265              bad  \n",
      "100989         0         0     3.7           Haze -5.476265              bad  \n",
      "\n",
      "[97176 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv(\"weather2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv=pd.read_csv(\"weather2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new x entry belongs to the cluster: 1 (bad)\n",
      "Score (probability density): 0.0402\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X =csv[['vector']].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "num_clusters = 2  # Number of flight condition categories\n",
    "gmm = GaussianMixture(n_components=num_clusters, random_state=42)\n",
    "gmm.fit(X_scaled)\n",
    "labels = gmm.predict(X_scaled)\n",
    "\n",
    "\n",
    "condition_labels = ['optimal', 'bad']\n",
    "x['flight_condition'] = [condition_labels[label] for label in labels]\n",
    "\n",
    "# Save the classified x\n",
    "x.to_csv('classified_weather_x.csv', index=False)\n",
    "\n",
    "# Save the scaler and GMM model\n",
    "scaler_filename = 'scaler.pkl'\n",
    "model_filename = 'gmm_model.pkl'\n",
    "\n",
    "with open(scaler_filename, 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(gmm, file)\n",
    "\n",
    "new_entry=[\"Clear\"]\n",
    "new_entry[0]=weather_to_float[new_entry[0]]\n",
    "\n",
    "new_entry_scaled = scaler.transform([new_entry])\n",
    "\n",
    "# Predict the cluster for the new entry\n",
    "cluster_label = gmm.predict(new_entry_scaled)[0]\n",
    "flight_condition = condition_labels[cluster_label]\n",
    "\n",
    "score = np.exp(gmm.score_samples(new_entry_scaled)[0])\n",
    "\n",
    "print(f\"The new x entry belongs to the cluster: {cluster_label} ({flight_condition})\")\n",
    "print(f\"Score (probability density): {score:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
